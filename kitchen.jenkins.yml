---
suites:
  - name: default
    run_list:
      - recipe[aws-parallelcluster::default]
    attributes:
      cluster:
        base_os: <%= ENV['BASE_OS'] %>

  - name: default_gpu
    run_list:
      - recipe[aws-parallelcluster::default]
    attributes:
      cluster:
        base_os: <%= ENV['BASE_OS'] %>
        nvidia:
          enabled: 'yes'

  - name: base_install
    run_list:
      - recipe[aws-parallelcluster::base_install]
    attributes:

  - name: base_install_gpu
    run_list:
      - recipe[aws-parallelcluster::base_install]
    attributes:
      cluster:
        nvidia:
          enabled: 'yes'

  - name: base_config_HeadNode
    run_list:
      - recipe[aws-parallelcluster::init]
      - recipe[aws-parallelcluster::base_config]
    attributes:
      cluster:
        node_type: 'HeadNode'
        stack_name: <%= ENV['AWS_STACK_NAME'] %>
        volume: <%= ENV['VOLUME'] %>
        region: <%= ENV['AWS_DEFAULT_REGION'] %>
        ephemeral_dir: <%= ENV['EPHEMERAL_DIR'] %>
        ebs_shared_dirs: <%= ENV['EBS_SHARED_DIRS'] %>
        cluster_user: <%= ENV['CLUSTER_USER'] %>
        # base_os is one of the base OSs supported by pcluster
        base_os: <%= ENV['BASE_OS'] %>
        custom_node_package: <%= ENV['PARALLELCLUSTER_NODE_URL'] %>
        # os attribute is used in pipeline code. i.e. centos7, centos7-custom
        os: <%= ENV['OS'] %>

  - name: slurm_config_HeadNode_x86_64
    run_list: &run_lists_slurm_config_HeadNode
      - recipe[aws-parallelcluster::init]
      - recipe[aws-parallelcluster::config]
      - recipe[aws-parallelcluster::finalize]
      - recipe[aws-parallelcluster::tests]
    attributes: &attributes_slurm_config_HeadNode
      kitchen: true
      cluster:
        node_type: 'HeadNode'
        scheduler: 'slurm'
        stack_name: <%= ENV['AWS_STACK_NAME'] %>
        volume: <%= ENV['VOLUME'] %>
        region: <%= ENV['AWS_DEFAULT_REGION'] %>
        ephemeral_dir: <%= ENV['EPHEMERAL_DIR'] %>
        ebs_shared_dirs: <%= ENV['EBS_SHARED_DIRS'] %>
        cluster_user: <%= ENV['CLUSTER_USER'] %>
        ddb_table: <%= ENV['DDB_TABLE'] %>
        slurm_ddb_table: <%= ENV['DDB_TABLE'] %>
        # base_os is one of the base OSs supported by pcluster
        base_os: <%= ENV['BASE_OS'] %>
        custom_node_package: <%= ENV['PARALLELCLUSTER_NODE_URL'] %>
        cluster_s3_bucket: <%= ENV['CLUSTER_CONFIG_S3_BUCKET'] %>
        cluster_config_s3_key: <%= ENV['CLUSTER_CONFIG_S3_KEY'] %>
        instance_types_data_s3_key: <%= ENV['INSTANCE_TYPES_DATA_S3_KEY'] %>
        # os attribute is used in pipeline code. i.e. centos7, centos7-custom
        os: <%= ENV['OS'] %>
        dcv_enabled: 'head_node'
        dcv_port: '8443'
        enable_intel_hpc_platform: "<%= ENV['ENABLE_INTEL_HPC_PLATFORM'] %>"
        enable_efa: 'compute'
        nvidia:
          enabled: <%= ENV['NVIDIA_ENABLED'] %>

  - name: slurm_config_HeadNode_arm64
    run_list: *run_lists_slurm_config_HeadNode
    attributes: *attributes_slurm_config_HeadNode

  - name: scheduler_plugin_config_HeadNode_x86_64
    run_list: &run_lists_scheduler_plugin_config_HeadNode
      - recipe[aws-parallelcluster::tests_mock]
      - recipe[aws-parallelcluster::init]
      - recipe[aws-parallelcluster::config]
      - recipe[aws-parallelcluster::finalize]
      - recipe[aws-parallelcluster::tests]
    attributes: &attributes_scheduler_plugin_config_HeadNode
      kitchen: true
      cluster:
        node_type: 'HeadNode'
        scheduler: 'plugin'
        stack_name: <%= ENV['AWS_STACK_NAME'] %>
        volume: <%= ENV['VOLUME'] %>
        region: <%= ENV['AWS_DEFAULT_REGION'] %>
        ephemeral_dir: <%= ENV['EPHEMERAL_DIR'] %>
        ebs_shared_dirs: <%= ENV['EBS_SHARED_DIRS'] %>
        cluster_user: <%= ENV['CLUSTER_USER'] %>
        ddb_table: <%= ENV['DDB_TABLE'] %>
        # base_os is one of the base OSs supported by pcluster
        base_os: <%= ENV['BASE_OS'] %>
        custom_node_package: <%= ENV['PARALLELCLUSTER_NODE_URL'] %>
        cluster_s3_bucket: <%= ENV['CLUSTER_CONFIG_S3_BUCKET'] %>
        cluster_config_s3_key: <%= ENV['CLUSTER_CONFIG_S3_KEY'] %>
        instance_types_data_s3_key: <%= ENV['INSTANCE_TYPES_DATA_S3_KEY'] %>
        # os attribute is used in pipeline code. i.e. centos7, centos7-custom
        os: <%= ENV['OS'] %>
        dcv_enabled: 'head_node'
        dcv_port: '8443'
        enable_intel_hpc_platform: "<%= ENV['ENABLE_INTEL_HPC_PLATFORM'] %>"
        enable_efa: 'compute'
        nvidia:
          enabled: <%= ENV['NVIDIA_ENABLED'] %>

  - name: scheduler_plugin_config_HeadNode_arm64
    run_list: *run_lists_scheduler_plugin_config_HeadNode
    attributes: *attributes_scheduler_plugin_config_HeadNode

  - name: awsbatch_config_HeadNode_x86_64
    run_list: &run_lists_awsbatch_config_HeadNode
      - recipe[aws-parallelcluster::init]
      - recipe[aws-parallelcluster::config]
      - recipe[aws-parallelcluster::finalize]
      - recipe[aws-parallelcluster::tests]
    attributes: &attributes_awsbatch_config_HeadNode
      kitchen: true
      cluster:
        node_type: 'HeadNode'
        scheduler: 'awsbatch'
        stack_name: <%= ENV['AWS_STACK_NAME'] %>
        volume: <%= ENV['VOLUME'] %>
        region: <%= ENV['AWS_DEFAULT_REGION'] %>
        ephemeral_dir: <%= ENV['EPHEMERAL_DIR'] %>
        ebs_shared_dirs: <%= ENV['EBS_SHARED_DIRS'] %>
        cluster_user: <%= ENV['CLUSTER_USER'] %>
        ddb_table: <%= ENV['DDB_TABLE'] %>
        # base_os is one of the base OSs supported by pcluster
        base_os: <%= ENV['BASE_OS'] %>
        custom_node_package: <%= ENV['PARALLELCLUSTER_NODE_URL'] %>
        cluster_s3_bucket: <%= ENV['CLUSTER_CONFIG_S3_BUCKET'] %>
        cluster_config_s3_key: <%= ENV['CLUSTER_CONFIG_S3_KEY'] %>
        instance_types_data_s3_key: <%= ENV['INSTANCE_TYPES_DATA_S3_KEY'] %>
        # os attribute is used in pipeline code. i.e. centos7, centos7-custom
        os: <%= ENV['OS'] %>
        dcv_enabled: 'head_node'
        dcv_port: '8443'
        custom_awsbatchcli_package: <%= ENV['CUSTOM_AWSBATCHCLI_URL'] %>
        nvidia:
          enabled: <%= ENV['NVIDIA_ENABLED'] %>

  - name: awsbatch_config_HeadNode_arm64
    run_list: *run_lists_awsbatch_config_HeadNode
    attributes: *attributes_awsbatch_config_HeadNode

  - name: slurm_config_ComputeFleet_x86_64
    run_list: &run_lists_slurm_config_ComputeFleet
      - recipe[aws-parallelcluster::init]
      - recipe[aws-parallelcluster::config]
      - recipe[aws-parallelcluster::finalize]
      - recipe[aws-parallelcluster::tests]
    attributes: &attributes_slurm_config_ComputeFleet
      kitchen: true
      cluster:
        node_type: 'ComputeFleet'
        scheduler: 'slurm'
        stack_name: <%= ENV['AWS_STACK_NAME'] %>
        volume: <%= ENV['VOLUME'] %>
        region: <%= ENV['AWS_DEFAULT_REGION'] %>
        ephemeral_dir: <%= ENV['EPHEMERAL_DIR'] %>
        ebs_shared_dirs: <%= ENV['EBS_SHARED_DIRS'] %>
        cluster_user: <%= ENV['CLUSTER_USER'] %>
        head_node: <%= ENV['HEAD_NODE'] %>
        head_node_private_ip: <%= ENV['HEAD_NODE_PRIVATE_IP'] %>
        # base_os is one of the base OSs supported by pcluster
        base_os: <%= ENV['BASE_OS'] %>
        slurm_nodename: 'fake-dy-compute-1'
        custom_node_package: <%= ENV['PARALLELCLUSTER_NODE_URL'] %>
        cluster_s3_bucket: <%= ENV['CLUSTER_CONFIG_S3_BUCKET'] %>
        cluster_config_s3_key: <%= ENV['CLUSTER_CONFIG_S3_KEY'] %>
        instance_types_data_s3_key: <%= ENV['INSTANCE_TYPES_DATA_S3_KEY'] %>
        # os attribute is used in pipeline code. i.e. centos7, centos7-custom
        os: <%= ENV['OS'] %>
        dcv_enabled: 'head_node'
        dcv_port: '8443'
        enable_efa: 'compute'
        nvidia:
          enabled: <%= ENV['NVIDIA_ENABLED'] %>

  - name: slurm_config_ComputeFleet_arm64
    run_list: *run_lists_slurm_config_ComputeFleet
    attributes: *attributes_slurm_config_ComputeFleet

  - name: scheduler_plugin_config_ComputeFleet_x86_64
    run_list: &run_lists_scheduler_plugin_config_ComputeFleet
      - recipe[aws-parallelcluster::tests_mock]
      - recipe[aws-parallelcluster::init]
      - recipe[aws-parallelcluster::config]
      - recipe[aws-parallelcluster::finalize]
      - recipe[aws-parallelcluster::tests]
    attributes: &attributes_scheduler_plugin_config_ComputeFleet
      kitchen: true
      cluster:
        node_type: 'ComputeFleet'
        scheduler: 'plugin'
        stack_name: <%= ENV['AWS_STACK_NAME'] %>
        volume: <%= ENV['VOLUME'] %>
        region: <%= ENV['AWS_DEFAULT_REGION'] %>
        ephemeral_dir: <%= ENV['EPHEMERAL_DIR'] %>
        ebs_shared_dirs: <%= ENV['EBS_SHARED_DIRS'] %>
        cluster_user: <%= ENV['CLUSTER_USER'] %>
        head_node: <%= ENV['HEAD_NODE'] %>
        head_node_private_ip: <%= ENV['HEAD_NODE_PRIVATE_IP'] %>
        # base_os is one of the base OSs supported by pcluster
        base_os: <%= ENV['BASE_OS'] %>
        scheduler_plugin_nodename: 'fake-dy-compute-1'
        custom_node_package: <%= ENV['PARALLELCLUSTER_NODE_URL'] %>
        cluster_s3_bucket: <%= ENV['CLUSTER_CONFIG_S3_BUCKET'] %>
        cluster_config_s3_key: <%= ENV['CLUSTER_CONFIG_S3_KEY'] %>
        instance_types_data_s3_key: <%= ENV['INSTANCE_TYPES_DATA_S3_KEY'] %>
        # os attribute is used in pipeline code. i.e. centos7, centos7-custom
        os: <%= ENV['OS'] %>
        dcv_enabled: 'head_node'
        dcv_port: '8443'
        enable_efa: 'compute'
        nvidia:
          enabled: <%= ENV['NVIDIA_ENABLED'] %>

  - name: scheduler_plugin_config_ComputeFleet_arm64
    run_list: *run_lists_scheduler_plugin_config_ComputeFleet
    attributes: *attributes_scheduler_plugin_config_ComputeFleet
